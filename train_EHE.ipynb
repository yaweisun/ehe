{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293795a-edf1-48df-bca7-c2d1288883a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import AutoTokenizer, AutoModel\n",
    "from paddle.io import DataLoader\n",
    "import paddle\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "from paddlenlp.layers import LinearChainCrf, LinearChainCrfLoss, ViterbiDecoder\n",
    "from seqeval import metrics\n",
    "from easydict import EasyDict as edict\n",
    "from src.dataset import SequenceTaggingDataset\n",
    "from src.utils import get_metric\n",
    "from src.model import EHEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d806a-041a-4b25-8133-2a2b4cbd63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = edict(\n",
    "    {\n",
    "        \"bert_model_name\": \"bert-base-chinese\",\n",
    "        \"batch_size\": 32,\n",
    "        \"gpu\": 1,\n",
    "        \"dataset\": \"ehe\",\n",
    "        \"data_name\": \"data_with_features\",\n",
    "        \"early_stopping\": 20,\n",
    "        \"eval_step\": 10,\n",
    "        \"lr\": 1e-5,\n",
    "        \"crflr\": 1e-3,\n",
    "        \"log_base\": \"./log\",\n",
    "        \"result_base\": \"./result\"\n",
    "        \"pos_emb\": True,\n",
    "        \"emotion_emb\": True,\n",
    "        \"bilstm\": True,\n",
    "        \"crf\": True,\n",
    "        \"dropout\": 0.2,\n",
    "        \"emotion_vocab_size\": 2,\n",
    "        \"checkpoint_path\": \"checkpoints\"\n",
    "    }\n",
    ")\n",
    "if paddle.is_compiled_with_cuda() and config.gpu is not None:  \n",
    "    device = f\"gpu:{config.gpu}\"  \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "config.task_name = config.dataset\n",
    "if config.pos_emb:\n",
    "    config.task_name += \"_pos\"\n",
    "if config.emotion_emb:\n",
    "    config.task_name += \"_emotion\"\n",
    "if config.bilstm:\n",
    "    config.task_name += \"_bilstm\"\n",
    "if config.crf:\n",
    "    config.task_name += \"_crf\"\n",
    "config.task_name += \"_lr%s_crflr%s_dropout%s\" % (str(config.lr).replace(\"-\", \"_\"), str(config.crflr).replace(\"-\", \"_\"), str(config.dropout))\n",
    "print(config.task_name)\n",
    "config.log_dir = os.path.join(config.log_base, config.task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ab396-40a2-4981-b504-c07ae257fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置日志路径以、参数保存路径及测试结果路径\n",
    "os.makedirs(config.log_dir, exist_ok=True)\n",
    "os.makedirs(config.checkpoint_path, exist_ok=True)\n",
    "os.makedirs(config.result_base, exist_ok=True)\n",
    "config.checkpoint = \"./%s/%s.pdparams\" % (config.checkpoint_path, config.task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391d9f5-fb27-4d10-b291-92f124c1b432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a716a7-4029-4aa7-9042-930b8f13c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = json.load(open(\"./data/%s.json\" % (config.data_name)))\n",
    "config.pos_map = json.load(open(\"./data/pos_map.json\" ))\n",
    "config.label_map = json.load(open(\"./data/label_map.json\"))\n",
    "config.pos_vocab_size = len(config.pos_map)\n",
    "config.num_classes = len(config.label_map)\n",
    "id2label = {i: l for l, i in config.label_map.items()}\n",
    "id2label.update({config.num_classes: \"O\", config.num_classes+1: \"O\"})\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.bert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ea7ea-a76e-4a64-a054-b884af42e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EHEModel(config)\n",
    "\n",
    "# 将BERT模型参数和其他参数分开\n",
    "bert_params = []\n",
    "crf_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'bert' in name:\n",
    "        bert_params.append(param)\n",
    "    else:\n",
    "        crf_params.append(param)\n",
    "\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=config.lr, parameters=bert_params)\n",
    "crf_optimizer = paddle.optimizer.AdamW(learning_rate=config.crflr, parameters=crf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07978288-9190-4e34-af6a-0aff1fd5354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = d[\"train\"]\n",
    "eval_data = d[\"eval\"]\n",
    "test_data = d[\"test\"]\n",
    "max_length = 0\n",
    "for item in train_data + eval_data + test_data:\n",
    "    max_length = max(max_length, len(item[\"input_tokens\"]))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbbd9d-4622-4486-a58a-ad0257be1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceTaggingDataset(\n",
    "    train_data, config.bert_model_name, config.pos_map, config.label_map,\n",
    "    max_length, tokenizer=tokenizer\n",
    ")\n",
    "eval_dataset = SequenceTaggingDataset(\n",
    "    eval_data, config.bert_model_name, config.pos_map, config.label_map,\n",
    "    max_length, tokenizer=tokenizer\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99978dc3-7039-421f-9f7c-231c5943ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "step = 0\n",
    "best_f1 = 0.\n",
    "stop_count = config[\"early_stopping\"]\n",
    "epoch = 1\n",
    "to_stop = False\n",
    "model.train()\n",
    "while not to_stop:\n",
    "    progress_bar = tqdm.tqdm(total=len(train_dataloader), desc=f'Training Epoch {epoch}, Best F1: {best_f1:.4f}')\n",
    "    for batch_data in train_dataloader:\n",
    "        log_item = {}\n",
    "        preds, loss = model(**batch_data)\n",
    "        metric = get_metric(batch_data[\"labels\"].numpy(), preds.numpy(), batch_data[\"lengths\"].numpy(), id2label)\n",
    "        metric[\"loss\"] = float(loss)\n",
    "        log_item[\"train\"] = metric\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        crf_optimizer.step()\n",
    "        crf_optimizer.clear_grad()\n",
    "\n",
    "        if step % config.eval_step == 0:\n",
    "            model.eval()\n",
    "            eval_loss = 0.\n",
    "            eval_num = 0\n",
    "            preds_list = []\n",
    "            labels_list = []\n",
    "            lengths_list = []\n",
    "            for batch_data in eval_dataloader:\n",
    "                preds, loss = model(**batch_data)\n",
    "                preds_list.append(preds.numpy())\n",
    "                labels_list.append(batch_data[\"labels\"].numpy())\n",
    "                lengths_list.append(batch_data[\"lengths\"].numpy())\n",
    "                \n",
    "                n = batch_data[\"input_ids\"].shape[0]\n",
    "                eval_loss += (float(loss) * n)\n",
    "                eval_num += n\n",
    "            eval_loss = eval_loss / eval_num\n",
    "            metric = get_metric(labels_list, preds_list, lengths_list, id2label)\n",
    "            metric[\"loss\"] = float(eval_loss)\n",
    "            log_item[\"eval\"] = metric\n",
    "            if best_f1 < metric[\"f1\"]:\n",
    "                best_f1 = metric[\"f1\"]\n",
    "                stop_count = config[\"early_stopping\"]\n",
    "                paddle.save(model.state_dict(), config.checkpoint)\n",
    "            else:\n",
    "                stop_count -= 1\n",
    "            metric[\"best_f1\"] = best_f1\n",
    "            log_item[\"eval\"] = metric\n",
    "            model.train()\n",
    "        json.dump(log_item, open(os.path.join(config.log_dir, \"%d.json\" % step), \"w\"))\n",
    "        if stop_count < 0:\n",
    "            to_stop = True\n",
    "            break\n",
    "\n",
    "        step += 1\n",
    "        progress_bar.update(1)  # Move progress bar\n",
    "        progress_bar.set_description(f'Training Epoch {epoch}, Best F1: {best_f1:.4f}')  # Update description\n",
    "    progress_bar.close()  # Close the progress bar at the end of each epoch\n",
    "    \n",
    "    # progress_bar.close()\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d0ae2-a2ae-46b3-bd72-56ded9f7d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试\n",
    "state_dict = paddle.load(config.checkpoint)\n",
    "model.set_state_dict(state_dict)\n",
    "model.eval()\n",
    "eval_loss = 0.\n",
    "eval_num = 0\n",
    "preds_list = []\n",
    "labels_list = []\n",
    "lengths_list = []\n",
    "test_dataset = SequenceTaggingDataset(\n",
    "    test_data, config.bert_model_name, config.pos_map, config.label_map, \n",
    "    max_length, tokenizer=tokenizer\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size)\n",
    "for batch_data in test_dataloader:\n",
    "    preds, loss = model(**batch_data)\n",
    "    preds_list.append(preds.numpy())\n",
    "    labels_list.append(batch_data[\"labels\"].numpy())\n",
    "    lengths_list.append(batch_data[\"lengths\"].numpy())\n",
    "    \n",
    "    n = batch_data[\"input_ids\"].shape[0]\n",
    "    eval_loss += (float(loss) * n)\n",
    "    eval_num += n\n",
    "eval_loss = eval_loss / eval_num\n",
    "metric = get_metric(labels_list, preds_list, lengths_list, id2label)\n",
    "metric[\"loss\"] = float(eval_loss)\n",
    "config[\"test_metric\"] = metric\n",
    "json.dump(config, open(\"./result/%s.json\" % config.task_name, \"w\"), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc81627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
